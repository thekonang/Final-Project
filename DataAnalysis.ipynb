{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing utilities function from utils.py\n",
    "<br>Loading the dataset.<br>\n",
    "<br>Initial Review: Utilize head() to view the dataset's first few rows or summary statistics. \n",
    "<br>This step helps in identifying any apparent issues with data types or missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SalesDate</th>\n",
       "      <th>ProductCategory</th>\n",
       "      <th>SalesAmount</th>\n",
       "      <th>CustomerAge</th>\n",
       "      <th>CustomerGender</th>\n",
       "      <th>CustomerLocation</th>\n",
       "      <th>ProductRatings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-10-15</td>\n",
       "      <td>Home Appliances</td>\n",
       "      <td>609</td>\n",
       "      <td>22</td>\n",
       "      <td>Male</td>\n",
       "      <td>USA</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-09-16</td>\n",
       "      <td>Clothing</td>\n",
       "      <td>1367</td>\n",
       "      <td>22</td>\n",
       "      <td>Female</td>\n",
       "      <td>Australia</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-09-06</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>1736</td>\n",
       "      <td>22</td>\n",
       "      <td>Male</td>\n",
       "      <td>UK</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-02-24</td>\n",
       "      <td>Female</td>\n",
       "      <td>1838</td>\n",
       "      <td>35</td>\n",
       "      <td>Clothing</td>\n",
       "      <td>India</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-09-24</td>\n",
       "      <td>Home Appliances</td>\n",
       "      <td>1829</td>\n",
       "      <td>35</td>\n",
       "      <td>Male</td>\n",
       "      <td>UK</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    SalesDate  ProductCategory SalesAmount  CustomerAge CustomerGender  \\\n",
       "0  2023-10-15  Home Appliances         609           22           Male   \n",
       "1  2023-09-16         Clothing        1367           22         Female   \n",
       "2  2022-09-06      Electronics        1736           22           Male   \n",
       "3  2023-02-24           Female        1838           35       Clothing   \n",
       "4  2022-09-24  Home Appliances        1829           35           Male   \n",
       "\n",
       "  CustomerLocation ProductRatings  \n",
       "0              USA              4  \n",
       "1        Australia              5  \n",
       "2               UK              2  \n",
       "3            India              2  \n",
       "4               UK              5  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import utils\n",
    "import pandas as pd\n",
    "# Load the dataset\n",
    "file_path = './data/adjusted_retail_sales_data_v2.csv'\n",
    "sales_data = utils.load_data(file_path)\n",
    "\n",
    "if sales_data is not None:\n",
    "    display(sales_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <h5>Initial Exploration : Analyzing the raw dataset.</h5>\n",
    "<p>It is often beneficial to perform initial exploratory data analysis, such as using <i><b>describe()</b></i> and <i><b>checking for missing values</b></i>\n",
    "<br>Before making any transformations or filtering the dataset.\n",
    "<br>This approach allows you to understand the dataset in its raw form and make informed decisions about how to clean and process it.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Descriptive Statistics:\n",
      "                         SalesDate ProductCategory   SalesAmount  CustomerAge  \\\n",
      "count                          997            1000  9.940000e+02  1000.000000   \n",
      "unique                         NaN               4           NaN          NaN   \n",
      "top                            NaN     Electronics           NaN          NaN   \n",
      "freq                           NaN             357           NaN          NaN   \n",
      "mean    2023-01-11 20:46:27.562688             NaN  2.867501e+03    29.177000   \n",
      "min            2022-01-02 00:00:00             NaN  2.200000e+01     2.000000   \n",
      "25%            2022-07-03 00:00:00             NaN  5.200000e+02    22.000000   \n",
      "50%            2023-01-26 00:00:00             NaN  9.870000e+02    22.000000   \n",
      "75%            2023-07-16 00:00:00             NaN  1.428000e+03    35.000000   \n",
      "max            2023-12-31 00:00:00             NaN  1.875000e+06   200.000000   \n",
      "std                            NaN             NaN  5.944267e+04    11.680844   \n",
      "\n",
      "       CustomerGender CustomerLocation  ProductRatings  \n",
      "count            1000              998      998.000000  \n",
      "unique              6                6             NaN  \n",
      "top              Male              USA             NaN  \n",
      "freq              488              207             NaN  \n",
      "mean              NaN              NaN        2.966934  \n",
      "min               NaN              NaN        1.000000  \n",
      "25%               NaN              NaN        2.000000  \n",
      "50%               NaN              NaN        3.000000  \n",
      "75%               NaN              NaN        4.000000  \n",
      "max               NaN              NaN       10.000000  \n",
      "std               NaN              NaN        1.404931  \n",
      "\n",
      "Categorical Columns Analysis:\n",
      "\n",
      "Categorical Columns Analysis:\n",
      "\n",
      "Column: ProductCategory\n",
      "ProductCategory\n",
      "Electronics        357\n",
      "Clothing           326\n",
      "Home Appliances    316\n",
      "Female               1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Column: CustomerGender\n",
      "CustomerGender\n",
      "Male              488\n",
      "Female            483\n",
      "Unknown            23\n",
      "Non-binary          4\n",
      "Clothing            1\n",
      "Did not answer      1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Column: CustomerLocation\n",
      "CustomerLocation\n",
      "USA          207\n",
      "UK           203\n",
      "Canada       201\n",
      "India        167\n",
      "Australia    113\n",
      "Japan        107\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\thekonang\\Documents\\TechPro Academy - DS\\Final Project\\utils.py:112: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  return rows_with_missing_values.style.applymap(highlight_nans)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_dbe68_row0_col0, #T_dbe68_row1_col2, #T_dbe68_row2_col2, #T_dbe68_row3_col2, #T_dbe68_row4_col0, #T_dbe68_row5_col0, #T_dbe68_row6_col2, #T_dbe68_row7_col2, #T_dbe68_row8_col6, #T_dbe68_row9_col6, #T_dbe68_row10_col5, #T_dbe68_row11_col5, #T_dbe68_row12_col2 {\n",
       "  background-color: red;\n",
       "}\n",
       "#T_dbe68_row0_col1, #T_dbe68_row0_col2, #T_dbe68_row0_col3, #T_dbe68_row0_col4, #T_dbe68_row0_col5, #T_dbe68_row0_col6, #T_dbe68_row1_col0, #T_dbe68_row1_col1, #T_dbe68_row1_col3, #T_dbe68_row1_col4, #T_dbe68_row1_col5, #T_dbe68_row1_col6, #T_dbe68_row2_col0, #T_dbe68_row2_col1, #T_dbe68_row2_col3, #T_dbe68_row2_col4, #T_dbe68_row2_col5, #T_dbe68_row2_col6, #T_dbe68_row3_col0, #T_dbe68_row3_col1, #T_dbe68_row3_col3, #T_dbe68_row3_col4, #T_dbe68_row3_col5, #T_dbe68_row3_col6, #T_dbe68_row4_col1, #T_dbe68_row4_col2, #T_dbe68_row4_col3, #T_dbe68_row4_col4, #T_dbe68_row4_col5, #T_dbe68_row4_col6, #T_dbe68_row5_col1, #T_dbe68_row5_col2, #T_dbe68_row5_col3, #T_dbe68_row5_col4, #T_dbe68_row5_col5, #T_dbe68_row5_col6, #T_dbe68_row6_col0, #T_dbe68_row6_col1, #T_dbe68_row6_col3, #T_dbe68_row6_col4, #T_dbe68_row6_col5, #T_dbe68_row6_col6, #T_dbe68_row7_col0, #T_dbe68_row7_col1, #T_dbe68_row7_col3, #T_dbe68_row7_col4, #T_dbe68_row7_col5, #T_dbe68_row7_col6, #T_dbe68_row8_col0, #T_dbe68_row8_col1, #T_dbe68_row8_col2, #T_dbe68_row8_col3, #T_dbe68_row8_col4, #T_dbe68_row8_col5, #T_dbe68_row9_col0, #T_dbe68_row9_col1, #T_dbe68_row9_col2, #T_dbe68_row9_col3, #T_dbe68_row9_col4, #T_dbe68_row9_col5, #T_dbe68_row10_col0, #T_dbe68_row10_col1, #T_dbe68_row10_col2, #T_dbe68_row10_col3, #T_dbe68_row10_col4, #T_dbe68_row10_col6, #T_dbe68_row11_col0, #T_dbe68_row11_col1, #T_dbe68_row11_col2, #T_dbe68_row11_col3, #T_dbe68_row11_col4, #T_dbe68_row11_col6, #T_dbe68_row12_col0, #T_dbe68_row12_col1, #T_dbe68_row12_col3, #T_dbe68_row12_col4, #T_dbe68_row12_col5, #T_dbe68_row12_col6 {\n",
       "  background-color: None;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_dbe68\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_dbe68_level0_col0\" class=\"col_heading level0 col0\" >SalesDate</th>\n",
       "      <th id=\"T_dbe68_level0_col1\" class=\"col_heading level0 col1\" >ProductCategory</th>\n",
       "      <th id=\"T_dbe68_level0_col2\" class=\"col_heading level0 col2\" >SalesAmount</th>\n",
       "      <th id=\"T_dbe68_level0_col3\" class=\"col_heading level0 col3\" >CustomerAge</th>\n",
       "      <th id=\"T_dbe68_level0_col4\" class=\"col_heading level0 col4\" >CustomerGender</th>\n",
       "      <th id=\"T_dbe68_level0_col5\" class=\"col_heading level0 col5\" >CustomerLocation</th>\n",
       "      <th id=\"T_dbe68_level0_col6\" class=\"col_heading level0 col6\" >ProductRatings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_dbe68_level0_row0\" class=\"row_heading level0 row0\" >7</th>\n",
       "      <td id=\"T_dbe68_row0_col0\" class=\"data row0 col0\" >NaT</td>\n",
       "      <td id=\"T_dbe68_row0_col1\" class=\"data row0 col1\" >Clothing</td>\n",
       "      <td id=\"T_dbe68_row0_col2\" class=\"data row0 col2\" >1656.000000</td>\n",
       "      <td id=\"T_dbe68_row0_col3\" class=\"data row0 col3\" >35</td>\n",
       "      <td id=\"T_dbe68_row0_col4\" class=\"data row0 col4\" >Male</td>\n",
       "      <td id=\"T_dbe68_row0_col5\" class=\"data row0 col5\" >USA</td>\n",
       "      <td id=\"T_dbe68_row0_col6\" class=\"data row0 col6\" >3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_dbe68_level0_row1\" class=\"row_heading level0 row1\" >18</th>\n",
       "      <td id=\"T_dbe68_row1_col0\" class=\"data row1 col0\" >2023-12-22 00:00:00</td>\n",
       "      <td id=\"T_dbe68_row1_col1\" class=\"data row1 col1\" >Clothing</td>\n",
       "      <td id=\"T_dbe68_row1_col2\" class=\"data row1 col2\" >nan</td>\n",
       "      <td id=\"T_dbe68_row1_col3\" class=\"data row1 col3\" >35</td>\n",
       "      <td id=\"T_dbe68_row1_col4\" class=\"data row1 col4\" >Male</td>\n",
       "      <td id=\"T_dbe68_row1_col5\" class=\"data row1 col5\" >Canada</td>\n",
       "      <td id=\"T_dbe68_row1_col6\" class=\"data row1 col6\" >5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_dbe68_level0_row2\" class=\"row_heading level0 row2\" >65</th>\n",
       "      <td id=\"T_dbe68_row2_col0\" class=\"data row2 col0\" >2023-08-09 00:00:00</td>\n",
       "      <td id=\"T_dbe68_row2_col1\" class=\"data row2 col1\" >Electronics</td>\n",
       "      <td id=\"T_dbe68_row2_col2\" class=\"data row2 col2\" >nan</td>\n",
       "      <td id=\"T_dbe68_row2_col3\" class=\"data row2 col3\" >35</td>\n",
       "      <td id=\"T_dbe68_row2_col4\" class=\"data row2 col4\" >Female</td>\n",
       "      <td id=\"T_dbe68_row2_col5\" class=\"data row2 col5\" >Japan</td>\n",
       "      <td id=\"T_dbe68_row2_col6\" class=\"data row2 col6\" >3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_dbe68_level0_row3\" class=\"row_heading level0 row3\" >72</th>\n",
       "      <td id=\"T_dbe68_row3_col0\" class=\"data row3 col0\" >2023-09-17 00:00:00</td>\n",
       "      <td id=\"T_dbe68_row3_col1\" class=\"data row3 col1\" >Home Appliances</td>\n",
       "      <td id=\"T_dbe68_row3_col2\" class=\"data row3 col2\" >nan</td>\n",
       "      <td id=\"T_dbe68_row3_col3\" class=\"data row3 col3\" >35</td>\n",
       "      <td id=\"T_dbe68_row3_col4\" class=\"data row3 col4\" >Male</td>\n",
       "      <td id=\"T_dbe68_row3_col5\" class=\"data row3 col5\" >USA</td>\n",
       "      <td id=\"T_dbe68_row3_col6\" class=\"data row3 col6\" >3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_dbe68_level0_row4\" class=\"row_heading level0 row4\" >73</th>\n",
       "      <td id=\"T_dbe68_row4_col0\" class=\"data row4 col0\" >NaT</td>\n",
       "      <td id=\"T_dbe68_row4_col1\" class=\"data row4 col1\" >Home Appliances</td>\n",
       "      <td id=\"T_dbe68_row4_col2\" class=\"data row4 col2\" >710.000000</td>\n",
       "      <td id=\"T_dbe68_row4_col3\" class=\"data row4 col3\" >35</td>\n",
       "      <td id=\"T_dbe68_row4_col4\" class=\"data row4 col4\" >Female</td>\n",
       "      <td id=\"T_dbe68_row4_col5\" class=\"data row4 col5\" >India</td>\n",
       "      <td id=\"T_dbe68_row4_col6\" class=\"data row4 col6\" >4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_dbe68_level0_row5\" class=\"row_heading level0 row5\" >91</th>\n",
       "      <td id=\"T_dbe68_row5_col0\" class=\"data row5 col0\" >NaT</td>\n",
       "      <td id=\"T_dbe68_row5_col1\" class=\"data row5 col1\" >Home Appliances</td>\n",
       "      <td id=\"T_dbe68_row5_col2\" class=\"data row5 col2\" >994.000000</td>\n",
       "      <td id=\"T_dbe68_row5_col3\" class=\"data row5 col3\" >35</td>\n",
       "      <td id=\"T_dbe68_row5_col4\" class=\"data row5 col4\" >Female</td>\n",
       "      <td id=\"T_dbe68_row5_col5\" class=\"data row5 col5\" >USA</td>\n",
       "      <td id=\"T_dbe68_row5_col6\" class=\"data row5 col6\" >5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_dbe68_level0_row6\" class=\"row_heading level0 row6\" >290</th>\n",
       "      <td id=\"T_dbe68_row6_col0\" class=\"data row6 col0\" >2023-09-19 00:00:00</td>\n",
       "      <td id=\"T_dbe68_row6_col1\" class=\"data row6 col1\" >Clothing</td>\n",
       "      <td id=\"T_dbe68_row6_col2\" class=\"data row6 col2\" >nan</td>\n",
       "      <td id=\"T_dbe68_row6_col3\" class=\"data row6 col3\" >22</td>\n",
       "      <td id=\"T_dbe68_row6_col4\" class=\"data row6 col4\" >Female</td>\n",
       "      <td id=\"T_dbe68_row6_col5\" class=\"data row6 col5\" >India</td>\n",
       "      <td id=\"T_dbe68_row6_col6\" class=\"data row6 col6\" >1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_dbe68_level0_row7\" class=\"row_heading level0 row7\" >472</th>\n",
       "      <td id=\"T_dbe68_row7_col0\" class=\"data row7 col0\" >2022-04-27 00:00:00</td>\n",
       "      <td id=\"T_dbe68_row7_col1\" class=\"data row7 col1\" >Home Appliances</td>\n",
       "      <td id=\"T_dbe68_row7_col2\" class=\"data row7 col2\" >nan</td>\n",
       "      <td id=\"T_dbe68_row7_col3\" class=\"data row7 col3\" >35</td>\n",
       "      <td id=\"T_dbe68_row7_col4\" class=\"data row7 col4\" >Unknown</td>\n",
       "      <td id=\"T_dbe68_row7_col5\" class=\"data row7 col5\" >Canada</td>\n",
       "      <td id=\"T_dbe68_row7_col6\" class=\"data row7 col6\" >3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_dbe68_level0_row8\" class=\"row_heading level0 row8\" >487</th>\n",
       "      <td id=\"T_dbe68_row8_col0\" class=\"data row8 col0\" >2023-04-16 00:00:00</td>\n",
       "      <td id=\"T_dbe68_row8_col1\" class=\"data row8 col1\" >Home Appliances</td>\n",
       "      <td id=\"T_dbe68_row8_col2\" class=\"data row8 col2\" >801.000000</td>\n",
       "      <td id=\"T_dbe68_row8_col3\" class=\"data row8 col3\" >22</td>\n",
       "      <td id=\"T_dbe68_row8_col4\" class=\"data row8 col4\" >Male</td>\n",
       "      <td id=\"T_dbe68_row8_col5\" class=\"data row8 col5\" >USA</td>\n",
       "      <td id=\"T_dbe68_row8_col6\" class=\"data row8 col6\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_dbe68_level0_row9\" class=\"row_heading level0 row9\" >570</th>\n",
       "      <td id=\"T_dbe68_row9_col0\" class=\"data row9 col0\" >2023-10-21 00:00:00</td>\n",
       "      <td id=\"T_dbe68_row9_col1\" class=\"data row9 col1\" >Clothing</td>\n",
       "      <td id=\"T_dbe68_row9_col2\" class=\"data row9 col2\" >1822.000000</td>\n",
       "      <td id=\"T_dbe68_row9_col3\" class=\"data row9 col3\" >22</td>\n",
       "      <td id=\"T_dbe68_row9_col4\" class=\"data row9 col4\" >Male</td>\n",
       "      <td id=\"T_dbe68_row9_col5\" class=\"data row9 col5\" >Canada</td>\n",
       "      <td id=\"T_dbe68_row9_col6\" class=\"data row9 col6\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_dbe68_level0_row10\" class=\"row_heading level0 row10\" >814</th>\n",
       "      <td id=\"T_dbe68_row10_col0\" class=\"data row10 col0\" >2022-11-16 00:00:00</td>\n",
       "      <td id=\"T_dbe68_row10_col1\" class=\"data row10 col1\" >Electronics</td>\n",
       "      <td id=\"T_dbe68_row10_col2\" class=\"data row10 col2\" >1547.000000</td>\n",
       "      <td id=\"T_dbe68_row10_col3\" class=\"data row10 col3\" >35</td>\n",
       "      <td id=\"T_dbe68_row10_col4\" class=\"data row10 col4\" >Male</td>\n",
       "      <td id=\"T_dbe68_row10_col5\" class=\"data row10 col5\" >nan</td>\n",
       "      <td id=\"T_dbe68_row10_col6\" class=\"data row10 col6\" >3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_dbe68_level0_row11\" class=\"row_heading level0 row11\" >820</th>\n",
       "      <td id=\"T_dbe68_row11_col0\" class=\"data row11 col0\" >2022-02-08 00:00:00</td>\n",
       "      <td id=\"T_dbe68_row11_col1\" class=\"data row11 col1\" >Clothing</td>\n",
       "      <td id=\"T_dbe68_row11_col2\" class=\"data row11 col2\" >1563.000000</td>\n",
       "      <td id=\"T_dbe68_row11_col3\" class=\"data row11 col3\" >35</td>\n",
       "      <td id=\"T_dbe68_row11_col4\" class=\"data row11 col4\" >Male</td>\n",
       "      <td id=\"T_dbe68_row11_col5\" class=\"data row11 col5\" >nan</td>\n",
       "      <td id=\"T_dbe68_row11_col6\" class=\"data row11 col6\" >5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_dbe68_level0_row12\" class=\"row_heading level0 row12\" >926</th>\n",
       "      <td id=\"T_dbe68_row12_col0\" class=\"data row12 col0\" >2023-11-08 00:00:00</td>\n",
       "      <td id=\"T_dbe68_row12_col1\" class=\"data row12 col1\" >Electronics</td>\n",
       "      <td id=\"T_dbe68_row12_col2\" class=\"data row12 col2\" >nan</td>\n",
       "      <td id=\"T_dbe68_row12_col3\" class=\"data row12 col3\" >35</td>\n",
       "      <td id=\"T_dbe68_row12_col4\" class=\"data row12 col4\" >Female</td>\n",
       "      <td id=\"T_dbe68_row12_col5\" class=\"data row12 col5\" >UK</td>\n",
       "      <td id=\"T_dbe68_row12_col6\" class=\"data row12 col6\" >3.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2c420da8380>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Initial Exploration Conclusions ---\n",
      "\n",
      "\n",
      "--- Potential Outliers Analysis ---\n",
      "The 'SalesAmount' column may contain outliers as indicated by a high max/standard deviation ratio.\n",
      "The 'CustomerAge' column may contain outliers as indicated by a high max/standard deviation ratio.\n",
      "The 'ProductRatings' column may contain outliers as indicated by a high max/standard deviation ratio.\n"
     ]
    }
   ],
   "source": [
    "sales_data = utils.convert_data_types(sales_data,\n",
    "                                 date_cols=['SalesDate'],\n",
    "                                 numeric_cols=['SalesAmount','CustomerAge' , 'ProductRatings'] ,\n",
    "                                 categorical_cols=['ProductCategory' , 'CustomerGender','CustomerLocation'])\n",
    "\n",
    "\n",
    "if sales_data is not None:\n",
    "    utils.describe_statistics(sales_data) # Perform initial descriptive statistics analysis\n",
    "\n",
    "    # Additional Categorical Analysis\n",
    "    print(\"\\nCategorical Columns Analysis:\")\n",
    "\n",
    "    utils.analyze_categorical_columns(sales_data, \n",
    "        ['ProductCategory', 'CustomerGender', 'CustomerLocation'])  # Analyze categorical columns\n",
    "\n",
    "    # Check and print missing values\n",
    "    display(utils.find_rows_with_missing_values(sales_data))\n",
    "\n",
    "    # Conclusions from initial exploration\n",
    "    print(\"\\n--- Initial Exploration Conclusions ---\\n\")\n",
    "\n",
    "    # Analyze potential outliers in numeric columns\n",
    "    utils.analyze_outliers(sales_data, ['SalesAmount', 'CustomerAge', 'ProductRatings'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <h2>Data Cleaning and Transformation Steps</h2>\n",
    "\n",
    "<p><strong>1. Handling Missing Values:</strong></p>\n",
    "<ul>\n",
    "  <li><em>SalesAmount</em>: Impute missing values with the median or remove rows if missing values are not randomly distributed.</li>\n",
    "  <li><em>ProductRatings</em>: Impute missing values with the median or remove rows.</li>\n",
    "</ul>\n",
    "\n",
    "<p><strong>2. Addressing Outliers:</strong></p>\n",
    "<ul>\n",
    "  <li><em>SalesAmount</em>: Identify and handle outliers using methods like IQR. Options include capping, replacing, or removing these values.</li>\n",
    "  <li><em>ProductRatings</em>: Values outside the range of 1 to 5 should be corrected or removed.</li>\n",
    "</ul>\n",
    "\n",
    "<p><strong>3. Correcting Data Types:</strong></p>\n",
    "<ul>\n",
    "  <li>Convert <em>SalesDate</em> to datetime format.</li>\n",
    "  <li>Ensure <em>SalesAmount</em> and <em>ProductRatings</em> are numeric.</li>\n",
    "</ul>\n",
    "\n",
    "<p><strong>4. Ensuring Data Consistency:</strong></p>\n",
    "<ul>\n",
    "  <li>Standardize categories in <em>ProductCategory</em>, <em>CustomerGender</em>, and <em>CustomerLocation</em>.</li>\n",
    "</ul>\n",
    "\n",
    "<p><strong>5. Filtering Inconsistent Data:</strong></p>\n",
    "<ul>\n",
    "  <li>Remove rows with invalid categories in <em>ProductCategory</em>, <em>CustomerGender</em>, or <em>CustomerLocation</em>.</li>\n",
    "</ul>\n",
    "\n",
    "<p><strong>6. Feature Engineering (if applicable):</strong></p>\n",
    "<ul>\n",
    "  <li>Create new features like month or year from <em>SalesDate</em>.</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing Values After Cleaning:\n",
      "SalesDate           3\n",
      "ProductCategory     0\n",
      "SalesAmount         0\n",
      "CustomerAge         0\n",
      "CustomerGender      0\n",
      "CustomerLocation    2\n",
      "ProductRatings      0\n",
      "Month               3\n",
      "Year                3\n",
      "dtype: int64\n",
      "\n",
      "Descriptive Statistics After Cleaning:\n",
      "       SalesAmount  ProductRatings\n",
      "count   986.000000      986.000000\n",
      "mean    980.397566        2.961460\n",
      "std     536.551834        1.385397\n",
      "min      22.000000        1.000000\n",
      "25%     520.000000        2.000000\n",
      "50%     987.000000        3.000000\n",
      "75%    1425.750000        4.000000\n",
      "max    1994.000000        5.000000\n",
      "\n",
      "--- Post-Cleaning Exploration Conclusions ---\n",
      "There are still missing values that need further attention.\n",
      "\n",
      "--- Potential Outliers Analysis ---\n",
      "The 'SalesAmount' column may contain outliers as indicated by a high max/standard deviation ratio.\n",
      "The 'CustomerAge' column may contain outliers as indicated by a high max/standard deviation ratio.\n",
      "The 'ProductRatings' column may contain outliers as indicated by a high max/standard deviation ratio.\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'sales_data.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 49\u001b[0m\n\u001b[0;32m     46\u001b[0m     utils\u001b[38;5;241m.\u001b[39manalyze_outliers(sales_data, [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSalesAmount\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCustomerAge\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProductRatings\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     48\u001b[0m \u001b[38;5;66;03m# TODO check if needed # store to excel test\u001b[39;00m\n\u001b[1;32m---> 49\u001b[0m     \u001b[43msales_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msales_data.xlsx\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\core\\generic.py:2345\u001b[0m, in \u001b[0;36mNDFrame.to_excel\u001b[1;34m(self, excel_writer, sheet_name, na_rep, float_format, columns, header, index, index_label, startrow, startcol, engine, merge_cells, inf_rep, freeze_panes, storage_options, engine_kwargs)\u001b[0m\n\u001b[0;32m   2332\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mformats\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexcel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ExcelFormatter\n\u001b[0;32m   2334\u001b[0m formatter \u001b[38;5;241m=\u001b[39m ExcelFormatter(\n\u001b[0;32m   2335\u001b[0m     df,\n\u001b[0;32m   2336\u001b[0m     na_rep\u001b[38;5;241m=\u001b[39mna_rep,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2343\u001b[0m     inf_rep\u001b[38;5;241m=\u001b[39minf_rep,\n\u001b[0;32m   2344\u001b[0m )\n\u001b[1;32m-> 2345\u001b[0m \u001b[43mformatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2346\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexcel_writer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2347\u001b[0m \u001b[43m    \u001b[49m\u001b[43msheet_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msheet_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstartrow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstartrow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstartcol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstartcol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfreeze_panes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfreeze_panes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2352\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2354\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\io\\formats\\excel.py:946\u001b[0m, in \u001b[0;36mExcelFormatter.write\u001b[1;34m(self, writer, sheet_name, startrow, startcol, freeze_panes, engine, storage_options, engine_kwargs)\u001b[0m\n\u001b[0;32m    942\u001b[0m     need_save \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    943\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    944\u001b[0m     \u001b[38;5;66;03m# error: Cannot instantiate abstract class 'ExcelWriter' with abstract\u001b[39;00m\n\u001b[0;32m    945\u001b[0m     \u001b[38;5;66;03m# attributes 'engine', 'save', 'supported_extensions' and 'write_cells'\u001b[39;00m\n\u001b[1;32m--> 946\u001b[0m     writer \u001b[38;5;241m=\u001b[39m \u001b[43mExcelWriter\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[abstract]\u001b[39;49;00m\n\u001b[0;32m    947\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    948\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    949\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    950\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    951\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    952\u001b[0m     need_save \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    954\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\io\\excel\\_openpyxl.py:61\u001b[0m, in \u001b[0;36mOpenpyxlWriter.__init__\u001b[1;34m(self, path, engine, date_format, datetime_format, mode, storage_options, if_sheet_exists, engine_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mopenpyxl\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mworkbook\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Workbook\n\u001b[0;32m     59\u001b[0m engine_kwargs \u001b[38;5;241m=\u001b[39m combine_kwargs(engine_kwargs, kwargs)\n\u001b[1;32m---> 61\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m     62\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     63\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[43m    \u001b[49m\u001b[43mif_sheet_exists\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mif_sheet_exists\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;66;03m# ExcelWriter replaced \"a\" by \"r+\" to allow us to first read the excel file from\u001b[39;00m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;66;03m# the file and later write to it\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode:  \u001b[38;5;66;03m# Load from existing workbook\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:1263\u001b[0m, in \u001b[0;36mExcelWriter.__init__\u001b[1;34m(self, path, engine, date_format, datetime_format, mode, storage_options, if_sheet_exists, engine_kwargs)\u001b[0m\n\u001b[0;32m   1259\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handles \u001b[38;5;241m=\u001b[39m IOHandles(\n\u001b[0;32m   1260\u001b[0m     cast(IO[\u001b[38;5;28mbytes\u001b[39m], path), compression\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m}\n\u001b[0;32m   1261\u001b[0m )\n\u001b[0;32m   1262\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, ExcelWriter):\n\u001b[1;32m-> 1263\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1264\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[0;32m   1265\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1266\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cur_sheet \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1268\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m date_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\io\\common.py:872\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    864\u001b[0m             handle,\n\u001b[0;32m    865\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    868\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    869\u001b[0m         )\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m--> 872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    873\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[0;32m    875\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'sales_data.xlsx'"
     ]
    }
   ],
   "source": [
    "# ... [Code for data cleaning and transformation]\n",
    "if sales_data is not None:\n",
    "    # Assuming sales_data is already loaded and initial exploration is done\n",
    "    \n",
    "    # Filtering Inconsistent Data\n",
    "    sales_data = utils.filter_data(sales_data, 'ProductCategory', valid_values= ['Clothing', 'Electronics', 'Home Appliances'])\n",
    "    sales_data = utils.filter_data(sales_data, 'CustomerGender', valid_values=['Male', 'Female', 'Non-binary'])\n",
    "    sales_data = utils.filter_data(sales_data, 'CustomerLocation',valid_values= ['Japan', 'Australia', 'India', 'USA', 'UK', 'Canada'])\n",
    "    sales_data = utils.filter_data(sales_data, 'ProductRatings',  None, min_value= 1 ,max_value= 5)\n",
    "    sales_data = utils.filter_data(sales_data, 'CustomerAge' ,None, min_value= 18 , max_value= 75) # BI ASSUMPTION : We are interested in a dynamic customer age  so we filter between 18-75\n",
    "    \n",
    "    # Handling Missing Values\n",
    "    sales_data['SalesAmount'].fillna(sales_data['SalesAmount'].median(), inplace=True)\n",
    "    sales_data['ProductRatings'].fillna(sales_data['ProductRatings'].median(), inplace=True)\n",
    "    \n",
    "    # Remove outliers from SalesAmount using the handle_outliers function\n",
    "    sales_data = utils.handle_outliers_IQR(sales_data, 'SalesAmount')\n",
    "\n",
    "    \n",
    "    # Correcting Data Types and Ensuring Data Consistency\n",
    "    sales_data = utils.convert_data_types(sales_data, date_cols=['SalesDate'], numeric_cols=['SalesAmount', 'ProductRatings'])\n",
    "    \n",
    "    # Feature Engineering\n",
    "    sales_data['Month'] = sales_data['SalesDate'].dt.month\n",
    "    sales_data['Year'] = sales_data['SalesDate'].dt.year\n",
    "    \n",
    "\n",
    "    # Exploration After Cleaning\n",
    "    # Final check for missing values and outliers\n",
    "    print(\"\\nMissing Values After Cleaning:\")\n",
    "    missing_values_post_cleaning = utils.check_missing_values(sales_data)\n",
    "    print(missing_values_post_cleaning)\n",
    "    \n",
    "    print(\"\\nDescriptive Statistics After Cleaning:\")\n",
    "    print(utils.describe_data(sales_data, ['SalesAmount', 'ProductRatings']))\n",
    "\n",
    "\n",
    "    # Example Conclusions from Post-Cleaning Exploration\n",
    "    print(\"\\n--- Post-Cleaning Exploration Conclusions ---\")\n",
    "    if missing_values_post_cleaning.sum() == 0:\n",
    "        print(\"Missing values have been successfully addressed.\")\n",
    "    else:\n",
    "        print(\"There are still missing values that need further attention.\")\n",
    "    \n",
    " # Analyze potential outliers in numeric columns\n",
    "    utils.analyze_outliers(sales_data, ['SalesAmount', 'CustomerAge', 'ProductRatings'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <h5>To analyze the patterns like average sales per product category, age distribution of customers, and typical product ratings from your dataset, we can use Pandas to group and aggregate the data. Let's break down the analysis into three parts:</h5>\n",
    "<ol>\n",
    "<li ><b>Average Sales per Product Category:</b> This will show how sales vary across different product categories.</li>\n",
    "<li><b>Age Distribution of Customers:</b> This will give insights into the demographic spread of the customers, which is vital for understanding your customer base.</li>\n",
    "<li><b>Typical Product Ratings: </b>This will reveal how products are rated on average, which can be indicative of product performance and customer satisfaction.</li>\n",
    "</ol>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_sales_category = sales_data.groupby('ProductCategory')['SalesAmount'].mean()\n",
    "print(\"Average Sales per Product Category:\")\n",
    "print(average_sales_category , \"\\n\")\n",
    "\n",
    "age_distribution = sales_data['CustomerAge'].value_counts().sort_index()\n",
    "print(\"Age Distribution of Customers:\")\n",
    "print(age_distribution, \"\\n\")\n",
    "\n",
    "average_product_ratings = sales_data['ProductRatings'].mean()\n",
    "print(f\"Average Product Ratings: {average_product_ratings}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sales Trends Over Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mticker\n",
    "import seaborn as sns\n",
    "\n",
    "# Ensure 'SalesAmount' is a numeric column\n",
    "sales_data['SalesAmount'] = pd.to_numeric(sales_data['SalesAmount'], errors='coerce')\n",
    "\n",
    "# Group data by date and sum up sales\n",
    "sales_over_time = sales_data.groupby(sales_data['SalesDate'].dt.to_period(\"M\"))['SalesAmount'].sum()\n",
    "\n",
    "# Plotting\n",
    "sales_over_time.plot(kind='line', figsize=(10, 6))\n",
    "\n",
    "# Use this to rotate the labels, if they overlap\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.title('Sales Trends Over Time')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Total Sales * 10^6')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Customer Demorgraphics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of customers by age\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(sales_data['CustomerAge'], kde=True)\n",
    "plt.title('Distribution of Customer Ages')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "# Distribution of customers by gender\n",
    "plt.figure(figsize=(10, 6))\n",
    "sales_data['CustomerGender'].value_counts().plot(kind='bar')\n",
    "plt.title('Distribution of Customer Gender')\n",
    "plt.xlabel('Gender')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Product Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "# Average sales per product category\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='ProductCategory', y='SalesAmount', data=sales_data, estimator=np.mean)\n",
    "plt.title('Average Sales per Product Category')\n",
    "plt.xlabel('Product Category')\n",
    "plt.ylabel('Average Sales')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# One-hot encode categorical variables\n",
    "categorical_cols = ['ProductCategory', 'CustomerGender', 'CustomerLocation']\n",
    "sales_data_encoded = pd.get_dummies(sales_data.drop('SalesDate' , axis =1), columns=categorical_cols)\n",
    "\n",
    "# Assuming 'SalesAmount' is your target variable\n",
    "X = sales_data_encoded.drop('SalesAmount', axis=1)\n",
    "\n",
    "y = sales_data_encoded['SalesAmount']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Create a linear regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "# Calculate R-squared and Mean Squared Error\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(f\"R-squared: {r2}\")\n",
    "print(f\"Mean Squared Error: {mse}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
